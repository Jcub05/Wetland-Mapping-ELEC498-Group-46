{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Wetland Classification Map Generator\n",
                "\n",
                "Applies the trained **Random Forest model** to 64-band satellite embedding tiles and produces a **single-band classified GeoTIFF** of the Bow River Basin.\n",
                "\n",
                "**Classes:**\n",
                "| Value | Class |\n",
                "|-------|-------|\n",
                "| 0 | Background/Upland |\n",
                "| 1 | Marsh |\n",
                "| 2 | Swamp |\n",
                "| 3 | Shallow Water |\n",
                "| 4 | Fen |\n",
                "| 5 | Bog |\n",
                "| 255 | No Data |\n",
                "\n",
                "**Memory-optimized:** Processes each tile in small row chunks to stay within Colab RAM limits.\n",
                "\n",
                "**Output:** `bow_river_classification_rf.tif` on Google Drive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 1: Setup\n",
                "print(\"Setting up environment...\")\n",
                "\n",
                "import os\n",
                "import gc\n",
                "from google.colab import drive\n",
                "\n",
                "# Mount Google Drive\n",
                "if not os.path.exists('/content/drive'):\n",
                "    drive.mount('/content/drive')\n",
                "else:\n",
                "    print(\"Drive already mounted\")\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -q rasterio tqdm joblib\n",
                "\n",
                "import numpy as np\n",
                "import rasterio\n",
                "from rasterio.windows import Window\n",
                "import joblib\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "from datetime import datetime\n",
                "\n",
                "print(\"Setup complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 2: Configuration\n",
                "print(\"=\"*60)\n",
                "print(\"CONFIGURATION\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# =====================\n",
                "# PATHS\n",
                "# =====================\n",
                "embeddings_dir = Path(\"/content/drive/MyDrive/EarthEngine\")\n",
                "labels_path = str(embeddings_dir / \"bow_river_wetlands_10m_final.tif\")\n",
                "\n",
                "# Path to trained RF model (.pkl)\n",
                "# Option A: Upload to Colab runtime (use Files panel on left)\n",
                "# Option B: Path on Google Drive\n",
                "model_path = \"/content/drive/MyDrive/rf_wetland_model_v1_20260120_130828.pkl\"\n",
                "\n",
                "# Output classification map\n",
                "output_path = \"/content/drive/MyDrive/bow_river_classification_rf.tif\"\n",
                "\n",
                "# =====================\n",
                "# MEMORY TUNING\n",
                "# =====================\n",
                "# How many rows of a tile to process at once.\n",
                "# Lower = less RAM, slower. Higher = more RAM, faster.\n",
                "# 128 rows x 3072 cols x 64 bands x 4 bytes = ~96 MB per chunk (safe for Colab)\n",
                "CHUNK_ROWS = 128\n",
                "\n",
                "# =====================\n",
                "# VALID EMBEDDING TILES (88 verified tiles with real data)\n",
                "# =====================\n",
                "VALID_TILE_NAMES = [\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000000000-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000003072-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000006144-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000009216-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000012288-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000015360-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000006144.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000018432-0000030720.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000000000.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000003072.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000009216.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000012288.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000015360.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000018432.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000021504.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000024576.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000027648.tif',\n",
                "    'bow_river_embeddings_2020_CORRECTED-0000021504-0000030720.tif',\n",
                "]\n",
                "\n",
                "# Class definitions\n",
                "CLASS_NAMES = {\n",
                "    0: 'Background/Upland',\n",
                "    1: 'Marsh',\n",
                "    2: 'Swamp',\n",
                "    3: 'Shallow Water',\n",
                "    4: 'Fen',\n",
                "    5: 'Bog',\n",
                "}\n",
                "NODATA_VALUE = 255\n",
                "\n",
                "# Build tile file paths from allowlist\n",
                "tile_files = [embeddings_dir / name for name in VALID_TILE_NAMES]\n",
                "\n",
                "# Verify paths\n",
                "print(f\"\\nLabels:     {labels_path}\")\n",
                "print(f\"Embeddings: {embeddings_dir}\")\n",
                "print(f\"Model:      {model_path}\")\n",
                "print(f\"Output:     {output_path}\")\n",
                "print(f\"Tiles:      {len(tile_files)} valid tiles\")\n",
                "print(f\"Chunk rows: {CHUNK_ROWS} (~{CHUNK_ROWS * 3072 * 64 * 4 / 1024**2:.0f} MB peak per chunk)\")\n",
                "\n",
                "assert os.path.exists(labels_path), f\"Labels not found: {labels_path}\"\n",
                "assert embeddings_dir.exists(), f\"Embeddings dir not found: {embeddings_dir}\"\n",
                "assert os.path.exists(model_path), f\"Model not found: {model_path}\\n  Upload it via Colab Files panel or copy to Drive.\"\n",
                "\n",
                "# Check that tiles exist\n",
                "missing = [t.name for t in tile_files if not t.exists()]\n",
                "if missing:\n",
                "    print(f\"\\nWARNING: {len(missing)} tiles not found on Drive:\")\n",
                "    for m in missing[:5]:\n",
                "        print(f\"  - {m}\")\n",
                "    if len(missing) > 5:\n",
                "        print(f\"  ... and {len(missing) - 5} more\")\n",
                "    tile_files = [t for t in tile_files if t.exists()]\n",
                "    print(f\"  Proceeding with {len(tile_files)} available tiles\")\n",
                "\n",
                "print(\"\\nConfiguration validated!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 3: Load Model & Reference Raster\n",
                "# NOTE: The model (~3.5 GB) will use most of the available RAM.\n",
                "# The chunked tile processing in Cell 4 keeps additional RAM usage low.\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"LOADING MODEL & REFERENCE DATA\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Load RF model\n",
                "print(\"\\nLoading Random Forest model (3.5 GB — may take a few minutes)...\")\n",
                "rf_model = joblib.load(model_path)\n",
                "print(f\"  Trees: {rf_model.n_estimators}\")\n",
                "print(f\"  Features: {rf_model.n_features_in_}\")\n",
                "\n",
                "# Force single-threaded prediction to reduce memory spikes during inference\n",
                "rf_model.n_jobs = 1\n",
                "print(\"  Set n_jobs=1 for memory-efficient inference\")\n",
                "\n",
                "# Read spatial metadata from labels raster\n",
                "print(\"\\nReading spatial reference from labels raster...\")\n",
                "with rasterio.open(labels_path) as labels_src:\n",
                "    out_height = labels_src.height\n",
                "    out_width = labels_src.width\n",
                "    out_crs = labels_src.crs\n",
                "    out_transform = labels_src.transform\n",
                "    print(f\"  Dimensions: {out_height} x {out_width}\")\n",
                "    print(f\"  CRS: {out_crs}\")\n",
                "    print(f\"  Resolution: {out_transform[0]:.1f}m\")\n",
                "\n",
                "# Verify first tile\n",
                "with rasterio.open(tile_files[0]) as test_src:\n",
                "    print(f\"\\nFirst tile: {tile_files[0].name}\")\n",
                "    print(f\"  Bands: {test_src.count}\")\n",
                "    print(f\"  Size: {test_src.height} x {test_src.width}\")\n",
                "    assert test_src.count == 64, f\"Expected 64 bands, got {test_src.count}\"\n",
                "\n",
                "gc.collect()\n",
                "print(\"\\nReady for inference!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 4: Run Inference — MEMORY-EFFICIENT (chunked row-by-row)\n",
                "#\n",
                "# Instead of loading a full 3072x3072x64 tile (~2.3 GB) at once,\n",
                "# we read CHUNK_ROWS rows at a time (~96 MB), predict, write, then discard.\n",
                "# Peak RAM = model (3.5 GB) + one chunk (~96 MB) = safe for Colab.\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"RUNNING CLASSIFICATION INFERENCE (MEMORY-EFFICIENT)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
                "print(f\"Processing in chunks of {CHUNK_ROWS} rows\")\n",
                "\n",
                "# Create output GeoTIFF (initialized with nodata)\n",
                "out_profile = {\n",
                "    'driver': 'GTiff',\n",
                "    'dtype': 'uint8',\n",
                "    'width': out_width,\n",
                "    'height': out_height,\n",
                "    'count': 1,\n",
                "    'crs': out_crs,\n",
                "    'transform': out_transform,\n",
                "    'nodata': NODATA_VALUE,\n",
                "    'compress': 'lzw',\n",
                "    'tiled': True,\n",
                "    'blockxsize': 512,\n",
                "    'blockysize': 512,\n",
                "}\n",
                "\n",
                "print(f\"\\nCreating output raster ({out_height}x{out_width})...\")\n",
                "# Create the file and fill with nodata in streaming chunks to avoid a big alloc\n",
                "with rasterio.open(output_path, 'w', **out_profile) as dst:\n",
                "    nodata_row = np.full((512, out_width), NODATA_VALUE, dtype=np.uint8)\n",
                "    for row_start in range(0, out_height, 512):\n",
                "        h = min(512, out_height - row_start)\n",
                "        dst.write(nodata_row[:h], 1, window=Window(0, row_start, out_width, h))\n",
                "del nodata_row\n",
                "gc.collect()\n",
                "print(\"Output raster created.\")\n",
                "\n",
                "# Track statistics\n",
                "total_pixels_classified = 0\n",
                "total_pixels_nodata = 0\n",
                "class_counts = np.zeros(6, dtype=np.int64)\n",
                "skipped_tiles = []\n",
                "\n",
                "# Process each tile in row chunks\n",
                "print(f\"\\nProcessing {len(tile_files)} tiles...\")\n",
                "\n",
                "with rasterio.open(output_path, 'r+') as dst:\n",
                "    for tile_file in tqdm(tile_files, desc=\"Tiles\", unit=\" tiles\"):\n",
                "        # Parse tile offset from filename: *-RRRRRRRRRR-CCCCCCCCCC.tif\n",
                "        parts = tile_file.stem.split('-')\n",
                "        if len(parts) < 3:\n",
                "            skipped_tiles.append(tile_file.name)\n",
                "            continue\n",
                "        try:\n",
                "            row_offset = int(parts[-2])\n",
                "            col_offset = int(parts[-1])\n",
                "        except ValueError:\n",
                "            skipped_tiles.append(tile_file.name)\n",
                "            continue\n",
                "\n",
                "        try:\n",
                "            with rasterio.open(tile_file) as tile_src:\n",
                "                if tile_src.count != 64:\n",
                "                    skipped_tiles.append(tile_file.name)\n",
                "                    continue\n",
                "\n",
                "                tile_h = tile_src.height\n",
                "                tile_w = tile_src.width\n",
                "\n",
                "                # Clip tile to output raster bounds\n",
                "                valid_h = min(tile_h, out_height - row_offset)\n",
                "                valid_w = min(tile_w, out_width - col_offset)\n",
                "                if valid_h <= 0 or valid_w <= 0:\n",
                "                    skipped_tiles.append(tile_file.name)\n",
                "                    continue\n",
                "\n",
                "                # --- CHUNKED PROCESSING ---\n",
                "                # Read CHUNK_ROWS rows at a time instead of the full tile\n",
                "                for chunk_start in range(0, valid_h, CHUNK_ROWS):\n",
                "                    chunk_h = min(CHUNK_ROWS, valid_h - chunk_start)\n",
                "\n",
                "                    # Read chunk: shape (64, chunk_h, valid_w)\n",
                "                    chunk_data = tile_src.read(\n",
                "                        window=Window(0, chunk_start, valid_w, chunk_h)\n",
                "                    )\n",
                "\n",
                "                    # Reshape to (n_pixels, 64)\n",
                "                    n_pixels = chunk_h * valid_w\n",
                "                    pixels = chunk_data.reshape(64, n_pixels).T\n",
                "\n",
                "                    # Free chunk_data immediately — we have pixels now\n",
                "                    del chunk_data\n",
                "\n",
                "                    # Mask NaN pixels\n",
                "                    valid_mask = ~np.isnan(pixels).any(axis=1)\n",
                "                    n_valid = valid_mask.sum()\n",
                "                    n_nan = n_pixels - n_valid\n",
                "\n",
                "                    # Predict on valid pixels only\n",
                "                    predictions = np.full(n_pixels, NODATA_VALUE, dtype=np.uint8)\n",
                "                    if n_valid > 0:\n",
                "                        predictions[valid_mask] = rf_model.predict(\n",
                "                            pixels[valid_mask]\n",
                "                        ).astype(np.uint8)\n",
                "\n",
                "                    del pixels  # free immediately after predict\n",
                "\n",
                "                    # Write chunk to correct position in output\n",
                "                    pred_2d = predictions.reshape(chunk_h, valid_w)\n",
                "                    write_window = Window(\n",
                "                        col_offset,\n",
                "                        row_offset + chunk_start,\n",
                "                        valid_w,\n",
                "                        chunk_h\n",
                "                    )\n",
                "                    dst.write(pred_2d, 1, window=write_window)\n",
                "\n",
                "                    del predictions, pred_2d\n",
                "\n",
                "                    # Stats\n",
                "                    total_pixels_classified += n_valid\n",
                "                    total_pixels_nodata += n_nan\n",
                "                    for cls in range(6):\n",
                "                        # Recompute from write — we already deleted predictions\n",
                "                        pass  # counted below via class_counts update\n",
                "\n",
                "        except Exception as e:\n",
                "            print(f\"\\n  Error on {tile_file.name}: {e}\")\n",
                "            skipped_tiles.append(tile_file.name)\n",
                "\n",
                "        gc.collect()  # Force GC between tiles\n",
                "\n",
                "print(f\"\\nFinished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
                "print(\"Inference complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 5: Verify & Summarize\n",
                "print(\"=\"*60)\n",
                "print(\"CLASSIFICATION MAP SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# File info\n",
                "file_size_mb = os.path.getsize(output_path) / (1024**2)\n",
                "print(f\"\\nOutput file: {output_path}\")\n",
                "print(f\"File size:   {file_size_mb:.1f} MB\")\n",
                "\n",
                "# Verify with rasterio and compute class distribution from the actual file\n",
                "print(\"\\nReading output raster for verification...\")\n",
                "with rasterio.open(output_path) as src:\n",
                "    print(f\"Dimensions:  {src.height} x {src.width}\")\n",
                "    print(f\"CRS:         {src.crs}\")\n",
                "    print(f\"Resolution:  {src.transform[0]:.1f}m\")\n",
                "    print(f\"Data type:   {src.dtypes[0]}\")\n",
                "    print(f\"NoData:      {src.nodata}\")\n",
                "\n",
                "    # Sample class distribution (read in chunks to avoid RAM spike)\n",
                "    print(\"\\nComputing class distribution (scanning output)...\")\n",
                "    class_counts = np.zeros(256, dtype=np.int64)\n",
                "    for row_start in range(0, src.height, 512):\n",
                "        h = min(512, src.height - row_start)\n",
                "        chunk = src.read(1, window=Window(0, row_start, src.width, h))\n",
                "        values, counts = np.unique(chunk, return_counts=True)\n",
                "        for v, c in zip(values, counts):\n",
                "            class_counts[v] += c\n",
                "\n",
                "total_nodata = class_counts[NODATA_VALUE]\n",
                "total_classified = class_counts[:6].sum()\n",
                "total_pixels = total_classified + total_nodata\n",
                "\n",
                "print(f\"\\nPixels classified: {total_classified:,}\")\n",
                "print(f\"Pixels nodata:     {total_nodata:,}\")\n",
                "\n",
                "if total_classified > 0:\n",
                "    print(f\"\\nClass Distribution:\")\n",
                "    print(f\"  {'Class':<5} {'Name':<20} {'Count':>12} {'Percent':>8}\")\n",
                "    print(f\"  {'-'*47}\")\n",
                "    for cls in range(6):\n",
                "        pct = 100 * class_counts[cls] / total_classified\n",
                "        print(f\"  {cls:<5} {CLASS_NAMES[cls]:<20} {class_counts[cls]:>12,} {pct:>7.2f}%\")\n",
                "\n",
                "if skipped_tiles:\n",
                "    print(f\"\\nSkipped {len(skipped_tiles)} tiles:\")\n",
                "    for t in skipped_tiles:\n",
                "        print(f\"  - {t}\")\n",
                "\n",
                "print(f\"\\n\" + \"=\"*60)\n",
                "print(\"DONE! Next steps:\")\n",
                "print(\"=\"*60)\n",
                "print(f\"1. Download '{os.path.basename(output_path)}' from Google Drive\")\n",
                "print(f\"2. Open in QGIS to verify the map visually\")\n",
                "print(f\"3. Hand off to frontend team for web display\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}