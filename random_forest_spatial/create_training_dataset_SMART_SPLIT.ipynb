{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wetland Training Dataset — Smart Spatial Split\n",
        "\n",
        "**Output:** `wetland_dataset_smart_split.npz`\n",
        "\n",
        "## Split Strategy\n",
        "\n",
        "A **mixed split** is used because Class 1 (only 19,225 pixels total) is entirely\n",
        "confined to the western portion of the study area and cannot be geographically split:\n",
        "\n",
        "| Class | Split type | Rationale |\n",
        "|-------|----------|----------|\n",
        "| 0, 2, 3, 4, 5 | **Geographic** — left/right column tile split | Pixels spread across entire map |\n",
        "| **1** | **Random 75/25 within its zone** | All 19,225 pixels in cols 1000–6311; no geo split possible |\n",
        "\n",
        "The geographic test region is tiles with `col_offset < TEST_COL_MAX` (~left 22% of map),\n",
        "which is where Class 2 is also concentrated, ensuring all classes appear in the test set.\n",
        "\n",
        "> **Documented limitation:** Because Class 1 pixels are spatially confined, its\n",
        "> train/test split is not geographically independent. This should be noted in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 1: Setup\n",
        "print('Setting up environment...')\n",
        "import os\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print('Drive already mounted')\n",
        "!pip install -q rasterio tqdm\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "print('Setup complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2: Configuration\n",
        "print('=' * 70)\n",
        "print('CONFIGURATION')\n",
        "print('=' * 70)\n",
        "\n",
        "labels_file    = '/content/drive/MyDrive/bow_river_wetlands_10m_final.tif'\n",
        "embeddings_dir = Path('/content/drive/MyDrive/EarthEngine')\n",
        "output_file    = '/content/drive/MyDrive/wetland_dataset_smart_split.npz'\n",
        "\n",
        "# ─── GEOGRAPHIC SPLIT (Classes 0, 2, 3, 4, 5) ────────────────────────\n",
        "# Hold out tiles with col_offset < TEST_COL_MAX as the test region.\n",
        "# 8192 comfortably encloses Class 2 (max col 7037) with buffer.\n",
        "TEST_COL_MAX = 8192\n",
        "\n",
        "# ─── CLASS 1 RANDOM SPLIT ─────────────────────────────────────────────\n",
        "# Class 1 is entirely in cols 1000–6311 (western zone).\n",
        "# We do a random 75/25 split of all its pixels.\n",
        "CLASS1_TRAIN_FRACTION = 0.75\n",
        "\n",
        "# Known bounding box of Class 1 pixels (from class distribution analysis)\n",
        "CLASS1_ROW_MIN, CLASS1_ROW_MAX = 764,  15197\n",
        "CLASS1_COL_MIN, CLASS1_COL_MAX = 1000,  6311\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# Per-class sample budgets\n",
        "train_samples_per_class = {\n",
        "    0: 600_000,\n",
        "    1: 19_225,   # all available — split handled separately\n",
        "    2: 150_000,\n",
        "    3: 500_000,\n",
        "    4: 150_000,\n",
        "    5: 100_000,\n",
        "}\n",
        "test_samples_per_class = {cls: max(1000, int(n * 0.25)) for cls, n in train_samples_per_class.items()}\n",
        "\n",
        "# Geographic budgets exclude Class 1 (handled separately)\n",
        "train_samples_geo = {cls: n for cls, n in train_samples_per_class.items() if cls != 1}\n",
        "test_samples_geo  = {cls: n for cls, n in test_samples_per_class.items()  if cls != 1}\n",
        "\n",
        "assert os.path.exists(labels_file),  'Labels TIF not found'\n",
        "assert embeddings_dir.exists(),       'Embeddings dir not found'\n",
        "\n",
        "print(f'Labels:        {labels_file}')\n",
        "print(f'Embeddings:    {embeddings_dir}')\n",
        "print(f'Output:        {output_file}')\n",
        "print(f'TEST_COL_MAX:  {TEST_COL_MAX}  (geo test = tiles with col < this value)')\n",
        "print(f'Class 1 split: random {CLASS1_TRAIN_FRACTION*100:.0f}/{(1-CLASS1_TRAIN_FRACTION)*100:.0f} within zone')\n",
        "print(f'\\nTrain target (geo classes): {sum(train_samples_geo.values()):,}')\n",
        "print(f'Test target  (geo classes): {sum(test_samples_geo.values()):,}')\n",
        "print('Configuration validated!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3: Discover tiles and do column-based geographic split\n",
        "print('=' * 70)\n",
        "print('DISCOVERING TILES — COLUMN SPLIT')\n",
        "print('=' * 70)\n",
        "\n",
        "all_tile_files = sorted(embeddings_dir.glob('*.tif'))\n",
        "print(f'Found {len(all_tile_files)} total tiles')\n",
        "\n",
        "tile_info = []\n",
        "for tf in all_tile_files:\n",
        "    parts = tf.stem.split('-')\n",
        "    if len(parts) >= 3:\n",
        "        try:\n",
        "            tile_info.append((int(parts[-2]), int(parts[-1]), tf))\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "print(f'Parseable tiles: {len(tile_info)}')\n",
        "\n",
        "# Geographic split: LEFT = test (contains Classes 1 and 2), RIGHT = train\n",
        "test_tiles  = [p for r, c, p in tile_info if c < TEST_COL_MAX]\n",
        "train_tiles = [p for r, c, p in tile_info if c >= TEST_COL_MAX]\n",
        "\n",
        "print(f'Train tiles (eastern, col >= {TEST_COL_MAX}): {len(train_tiles)}')\n",
        "print(f'Test  tiles (western, col <  {TEST_COL_MAX}): {len(test_tiles)}')\n",
        "print(f'Test fraction: {len(test_tiles)/len(tile_info)*100:.1f}% of all tiles')\n",
        "\n",
        "if not test_tiles:\n",
        "    raise RuntimeError('No test tiles found — check TEST_COL_MAX or tile naming.')\n",
        "\n",
        "print('\\nSpatial split defined!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4: Sample Class 1 separately (random 75/25 within its bounding zone)\n",
        "print('=' * 70)\n",
        "print('SAMPLING CLASS 1 (RANDOM SPLIT WITHIN ZONE)')\n",
        "print('=' * 70)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "class1_y_all, class1_x_all = [], []\n",
        "\n",
        "with rasterio.open(labels_file) as src:\n",
        "    windows = list(src.block_windows(1))\n",
        "    for block_id, window in tqdm(windows, desc='Scanning for Class 1'):\n",
        "        row_off = window.row_off\n",
        "        col_off = window.col_off\n",
        "        win_h   = window.height\n",
        "        win_w   = window.width\n",
        "\n",
        "        # Skip blocks outside Class 1's known bounding box\n",
        "        if row_off + win_h <= CLASS1_ROW_MIN or row_off > CLASS1_ROW_MAX:\n",
        "            continue\n",
        "        if col_off + win_w <= CLASS1_COL_MIN or col_off > CLASS1_COL_MAX:\n",
        "            continue\n",
        "\n",
        "        chunk = src.read(1, window=window)\n",
        "        y_loc, x_loc = np.where(chunk == 1)\n",
        "        if len(y_loc) == 0:\n",
        "            continue\n",
        "\n",
        "        class1_y_all.append(y_loc + row_off)\n",
        "        class1_x_all.append(x_loc + col_off)\n",
        "\n",
        "class1_y = np.concatenate(class1_y_all)\n",
        "class1_x = np.concatenate(class1_x_all)\n",
        "print(f'\\nTotal Class 1 pixels found: {len(class1_y):,}')\n",
        "\n",
        "# Random shuffle then 75/25 split\n",
        "shuf = np.random.permutation(len(class1_y))\n",
        "class1_y = class1_y[shuf]\n",
        "class1_x = class1_x[shuf]\n",
        "\n",
        "n_train1 = int(len(class1_y) * CLASS1_TRAIN_FRACTION)\n",
        "class1_train_y, class1_train_x = class1_y[:n_train1],  class1_x[:n_train1]\n",
        "class1_test_y,  class1_test_x  = class1_y[n_train1:],  class1_x[n_train1:]\n",
        "\n",
        "print(f'Class 1 train: {len(class1_train_y):,} pixels (random {CLASS1_TRAIN_FRACTION*100:.0f}%)')\n",
        "print(f'Class 1 test:  {len(class1_test_y):,} pixels (random {(1-CLASS1_TRAIN_FRACTION)*100:.0f}%)')\n",
        "print('\\n⚠ NOTE: Class 1 split is NOT geographically independent.')\n",
        "print('  This is documented as a known limitation (Class 1 is spatially confined).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Sample geographic classes (0, 2, 3, 4, 5) using tile-based column split\n",
        "print('=' * 70)\n",
        "print('SAMPLING GEOGRAPHIC CLASSES (0, 2, 3, 4, 5)')\n",
        "print('=' * 70)\n",
        "\n",
        "def sample_coords_from_tiles(tile_paths, samples_per_class, split_name):\n",
        "    \"\"\"Sample pixel coordinates only within the bounding box of the given tiles.\"\"\"\n",
        "    tile_info_local = []\n",
        "    for tf in tile_paths:\n",
        "        parts = tf.stem.split('-')\n",
        "        try:\n",
        "            r = int(parts[-2]); c = int(parts[-1])\n",
        "            with rasterio.open(tf) as s:\n",
        "                tile_info_local.append((r, c, s.height, s.width))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    bbox_row_min = min(r for r,c,h,w in tile_info_local)\n",
        "    bbox_row_max = max(r+h for r,c,h,w in tile_info_local)\n",
        "    bbox_col_min = min(c for r,c,h,w in tile_info_local)\n",
        "    bbox_col_max = max(c+w for r,c,h,w in tile_info_local)\n",
        "    print(f'\\n  {split_name} bbox: rows {bbox_row_min}–{bbox_row_max}, cols {bbox_col_min}–{bbox_col_max}')\n",
        "\n",
        "    sampled   = {cls: {'y': [], 'x': []} for cls in samples_per_class}\n",
        "    collected = {cls: 0 for cls in samples_per_class}\n",
        "\n",
        "    with rasterio.open(labels_file) as src:\n",
        "        windows = list(src.block_windows(1))\n",
        "        np.random.shuffle(windows)\n",
        "        for idx, (block_id, window) in tqdm(enumerate(windows), total=len(windows), desc=f'{split_name} blocks'):\n",
        "            row_off = window.row_off; col_off = window.col_off\n",
        "            win_h   = window.height;  win_w   = window.width\n",
        "            if row_off+win_h <= bbox_row_min or row_off >= bbox_row_max: continue\n",
        "            if col_off+win_w <= bbox_col_min or col_off >= bbox_col_max: continue\n",
        "\n",
        "            chunk = src.read(1, window=window)\n",
        "            for cls in samples_per_class:\n",
        "                if collected[cls] >= samples_per_class[cls]: continue\n",
        "                y_l, x_l = np.where(chunk == cls)\n",
        "                if len(y_l) == 0: continue\n",
        "                y_g = y_l + row_off; x_g = x_l + col_off\n",
        "                in_b = ((y_g>=bbox_row_min)&(y_g<bbox_row_max)&\n",
        "                        (x_g>=bbox_col_min)&(x_g<bbox_col_max))\n",
        "                y_g = y_g[in_b]; x_g = x_g[in_b]\n",
        "                if len(y_g) == 0: continue\n",
        "                needed = samples_per_class[cls] - collected[cls]\n",
        "                if len(y_g) > needed:\n",
        "                    idx_s = np.random.choice(len(y_g), needed, replace=False)\n",
        "                    y_g = y_g[idx_s]; x_g = x_g[idx_s]\n",
        "                sampled[cls]['y'].append(y_g)\n",
        "                sampled[cls]['x'].append(x_g)\n",
        "                collected[cls] += len(y_g)\n",
        "            if all(collected[c] >= samples_per_class[c] for c in samples_per_class):\n",
        "                print(f'\\n  Got all {split_name} samples after {idx+1} blocks'); break\n",
        "\n",
        "    print(f'  {split_name} summary:')\n",
        "    for cls in samples_per_class:\n",
        "        print(f'    Class {cls}: {collected[cls]:,} / {samples_per_class[cls]:,}')\n",
        "    return sampled, collected\n",
        "\n",
        "\n",
        "train_sampled_geo, _ = sample_coords_from_tiles(train_tiles, train_samples_geo, 'TRAIN (geo)')\n",
        "test_sampled_geo,  _ = sample_coords_from_tiles(test_tiles,  test_samples_geo,  'TEST (geo)')\n",
        "print('\\nGeographic class sampling complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 6: Consolidate all coordinates into flat arrays\n",
        "\n",
        "def consolidate_geo(sampled, budgets):\n",
        "    all_y, all_x, all_labels = [], [], []\n",
        "    for cls in budgets:\n",
        "        if not sampled[cls]['y']: continue\n",
        "        ys = np.concatenate(sampled[cls]['y'])\n",
        "        xs = np.concatenate(sampled[cls]['x'])\n",
        "        if len(ys) > budgets[cls]: ys, xs = ys[:budgets[cls]], xs[:budgets[cls]]\n",
        "        all_y.append(ys); all_x.append(xs)\n",
        "        all_labels.append(np.full(len(ys), cls))\n",
        "    return np.concatenate(all_y), np.concatenate(all_x), np.concatenate(all_labels)\n",
        "\n",
        "# Geo classes\n",
        "geo_train_y, geo_train_x, geo_train_lbl = consolidate_geo(train_sampled_geo, train_samples_geo)\n",
        "geo_test_y,  geo_test_x,  geo_test_lbl  = consolidate_geo(test_sampled_geo,  test_samples_geo)\n",
        "\n",
        "# Merge with Class 1 coords\n",
        "train_y = np.concatenate([geo_train_y, class1_train_y])\n",
        "train_x = np.concatenate([geo_train_x, class1_train_x])\n",
        "train_labels = np.concatenate([geo_train_lbl, np.ones(len(class1_train_y), dtype=np.int64)])\n",
        "\n",
        "test_y = np.concatenate([geo_test_y,  class1_test_y])\n",
        "test_x = np.concatenate([geo_test_x,  class1_test_x])\n",
        "test_labels = np.concatenate([geo_test_lbl, np.ones(len(class1_test_y), dtype=np.int64)])\n",
        "\n",
        "# Shuffle\n",
        "for arr_set in [(train_y, train_x, train_labels), (test_y, test_x, test_labels)]:\n",
        "    pass  # kept separate for shuffling below\n",
        "\n",
        "shuf_tr = np.random.permutation(len(train_labels))\n",
        "train_y, train_x, train_labels = train_y[shuf_tr], train_x[shuf_tr], train_labels[shuf_tr]\n",
        "\n",
        "shuf_te = np.random.permutation(len(test_labels))\n",
        "test_y,  test_x,  test_labels  = test_y[shuf_te],  test_x[shuf_te],  test_labels[shuf_te]\n",
        "\n",
        "print(f'Train coordinates: {len(train_labels):,}')\n",
        "print(f'  Classes in train: {np.unique(train_labels)}')\n",
        "print(f'Test  coordinates: {len(test_labels):,}')\n",
        "print(f'  Classes in test:  {np.unique(test_labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 7: Extract embeddings\n",
        "print('\\n' + '=' * 70)\n",
        "print('EXTRACTING EMBEDDINGS')\n",
        "print('=' * 70)\n",
        "\n",
        "def extract_embeddings(tile_files, y_indices, x_indices, desc):\n",
        "    n = len(y_indices)\n",
        "    X = np.zeros((n, 64), dtype=np.float32)\n",
        "    found = np.zeros(n, dtype=bool)\n",
        "    with tqdm(total=len(tile_files), desc=desc, unit=' tiles') as pbar:\n",
        "        for tf in tile_files:\n",
        "            try:\n",
        "                with rasterio.open(tf) as src:\n",
        "                    if src.count != 64: pbar.update(1); continue\n",
        "                    parts = tf.stem.split('-')\n",
        "                    try: r_off = int(parts[-2]); c_off = int(parts[-1])\n",
        "                    except: pbar.update(1); continue\n",
        "                    th, tw = src.height, src.width\n",
        "                    mask = ((y_indices>=r_off)&(y_indices<r_off+th)&\n",
        "                            (x_indices>=c_off)&(x_indices<c_off+tw))\n",
        "                    if mask.any():\n",
        "                        tile_data = src.read()\n",
        "                        if tile_data.shape[0] != 64: pbar.update(1); continue\n",
        "                        ly = y_indices[mask] - r_off\n",
        "                        lx = x_indices[mask] - c_off\n",
        "                        vals = tile_data[:, ly, lx].T\n",
        "                        valid = ~np.isnan(vals).any(axis=1)\n",
        "                        g_idx = np.where(mask)[0]\n",
        "                        X[g_idx[valid]] = vals[valid]\n",
        "                        found[g_idx[valid]] = True\n",
        "            except Exception as e:\n",
        "                print(f'\\nError {tf.name}: {e}')\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({'found': f'{found.sum():,}/{n:,}'})\n",
        "    print(f'  Extracted {found.sum():,} / {n:,}')\n",
        "    return X, found\n",
        "\n",
        "# TRAIN: geo classes come from eastern (train) tiles;\n",
        "#        Class 1 train pixels come from western (test) tiles.\n",
        "# We simply pass all_tile_files so the function finds each pixel in its correct tile.\n",
        "print('\\n-- TRAIN --')\n",
        "X_train_raw, train_found = extract_embeddings(all_tile_files, train_y, train_x, 'Train (all tiles)')\n",
        "X_train = X_train_raw[train_found]\n",
        "y_train = train_labels[train_found]\n",
        "\n",
        "print('\\n-- TEST --')\n",
        "X_test_raw, test_found = extract_embeddings(all_tile_files, test_y, test_x, 'Test (all tiles)')\n",
        "X_test = X_test_raw[test_found]\n",
        "y_test = test_labels[test_found]\n",
        "\n",
        "print(f'\\nFinal train set: {X_train.shape}')\n",
        "print(f'Final test set:  {X_test.shape}')\n",
        "print('Extraction complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 8: Compute class weights and save\n",
        "print('\\n' + '=' * 70)\n",
        "print('SAVING DATASET')\n",
        "print('=' * 70)\n",
        "\n",
        "unique_cls, counts = np.unique(y_train, return_counts=True)\n",
        "class_weights = np.zeros(6, dtype=np.float32)\n",
        "for cls, cnt in zip(unique_cls, counts):\n",
        "    class_weights[cls] = 1.0 / cnt\n",
        "class_weights = class_weights / class_weights.sum() * 6\n",
        "\n",
        "print('Class weights (from train):')\n",
        "for cls in range(6):\n",
        "    print(f'  Class {cls}: {class_weights[cls]:.4f}')\n",
        "\n",
        "np.savez_compressed(\n",
        "    output_file,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    class_weights=class_weights,\n",
        "    test_col_max=np.array(TEST_COL_MAX, dtype=np.int64),\n",
        ")\n",
        "\n",
        "print(f'\\nSaved: {output_file}')\n",
        "print(f'  X_train: {X_train.shape}  (eastern tiles + random Class 1)')\n",
        "print(f'  X_test:  {X_test.shape}   (western tiles + random Class 1)')\n",
        "print(f'  test_col_max: {TEST_COL_MAX}')\n",
        "print('\\nNext steps:')\n",
        "print('  1. Download wetland_dataset_smart_split.npz from Google Drive')\n",
        "print('  2. Place in repo root')\n",
        "print('  3. Run: python random_forest_spatial/model_rf_spatial.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 9: Verification\n",
        "print('\\n' + '=' * 70)\n",
        "print('VERIFICATION')\n",
        "print('=' * 70)\n",
        "\n",
        "d = np.load(output_file)\n",
        "print(f'Arrays: {list(d.keys())}')\n",
        "print(f'X_train: {d[\"X_train\"].shape}  NaN={np.isnan(d[\"X_train\"]).any()}')\n",
        "print(f'X_test:  {d[\"X_test\"].shape}   NaN={np.isnan(d[\"X_test\"]).any()}')\n",
        "print(f'y_train classes: {np.unique(d[\"y_train\"])}')\n",
        "print(f'y_test  classes: {np.unique(d[\"y_test\"])}')\n",
        "print(f'test_col_max:    {int(d[\"test_col_max\"])}')\n",
        "d.close()\n",
        "print('\\nVerification passed!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}