{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Wetland Training Dataset — Middle Row Band Split\n",
                "\n",
                "**Output:** `wetland_dataset_middle_split.npz`\n",
                "\n",
                "## Split Strategy\n",
                "\n",
                "Holds out a **horizontal strip from the middle of the map** (~rows 40%–60%) as the test region.\n",
                "Training uses tiles from both the **northern** and **southern** portions of the map.\n",
                "\n",
                "This eliminates the east/west domain shift problem from the column-based split because:\n",
                "- The model sees landscape features from **both sides** of the held-out region\n",
                "- All 6 wetland classes appear in the test band (Classes 1 & 2 row ranges overlap the middle strip)\n",
                "- No random within-zone fallback needed — **purely geographic split for all classes**\n",
                "\n",
                "| Class | Total pixels | Row range | In test band? |\n",
                "|-------|------------|----------|---------------|\n",
                "| 0 | 628M | 0–20,606 | ✅ |\n",
                "| 1 | 19,225 | 764–15,197 | ✅ |\n",
                "| 2 | 901,620 | 45–15,175 | ✅ |\n",
                "| 3 | 14.6M | 1–20,606 | ✅ |\n",
                "| 4 | 2.3M | 344–20,221 | ✅ |\n",
                "| 5 | 1.5M | 3–19,112 | ✅ |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 1: Setup\n",
                "import os, gc, shutil\n",
                "from google.colab import drive\n",
                "if not os.path.exists('/content/drive'):\n",
                "    drive.mount('/content/drive')\n",
                "else:\n",
                "    print('Drive already mounted')\n",
                "\n",
                "!pip install -q rasterio tqdm\n",
                "import numpy as np\n",
                "import rasterio\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "\n",
                "DRIVE_TILES = '/content/drive/MyDrive/EarthEngine'\n",
                "LOCAL_TILES  = '/content/EarthEngine'\n",
                "free_gb = shutil.disk_usage('/content').free / (1024**3)\n",
                "print(f'Free disk space: {free_gb:.1f} GB')\n",
                "\n",
                "if free_gb > 110 and not os.path.exists(LOCAL_TILES):\n",
                "    print('Copying tiles to local disk...')\n",
                "    !cp -r {DRIVE_TILES} {LOCAL_TILES}\n",
                "    TILES_PATH = LOCAL_TILES\n",
                "elif os.path.exists(LOCAL_TILES) and len(list(Path(LOCAL_TILES).glob('*.tif'))) > 0:\n",
                "    TILES_PATH = LOCAL_TILES\n",
                "    print('Local tiles already present.')\n",
                "else:\n",
                "    TILES_PATH = DRIVE_TILES\n",
                "    print(f'Reading from Drive ({free_gb:.1f} GB free). Extraction ~60-90 min.')\n",
                "\n",
                "print(f'Tile source: {TILES_PATH}')\n",
                "print('Setup complete!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 2: Configuration\n",
                "print('=' * 70)\n",
                "print('CONFIGURATION')\n",
                "print('=' * 70)\n",
                "\n",
                "labels_file    = '/content/drive/MyDrive/bow_river_wetlands_10m_final.tif'\n",
                "embeddings_dir = Path(TILES_PATH)\n",
                "output_file    = '/content/drive/MyDrive/wetland_dataset_middle_split.npz'\n",
                "\n",
                "# ─── MIDDLE ROW BAND SPLIT ──────────────────────────────────────────\n",
                "# Test = tiles whose row_offset falls in the middle [40%, 60%] of the\n",
                "# total tile row range. Gives a ~20% test band that overlaps Class 1\n",
                "# (rows 764-15197) and Class 2 (rows 45-15175), so both appear in\n",
                "# training (north + south) AND testing (middle).\n",
                "TEST_BAND_FRAC_LOW  = 0.40   # lower bound of test band (fraction of total row range)\n",
                "TEST_BAND_FRAC_HIGH = 0.60   # upper bound of test band\n",
                "# ────────────────────────────────────────────────────────────────────\n",
                "\n",
                "# Per-class sample budgets\n",
                "train_samples_per_class = {\n",
                "    0: 600_000,\n",
                "    1: 14_418,    # ~75% of all 19,225 Class 1 pixels (from north + south)\n",
                "    2: 150_000,\n",
                "    3: 500_000,\n",
                "    4: 150_000,\n",
                "    5: 100_000,\n",
                "}\n",
                "test_samples_per_class = {\n",
                "    0: 150_000,\n",
                "    1: 4_806,     # remaining ~25% of Class 1\n",
                "    2: 37_500,\n",
                "    3: 125_000,\n",
                "    4: 37_500,\n",
                "    5: 25_000,\n",
                "}\n",
                "\n",
                "assert os.path.exists(labels_file), f'Labels TIF not found: {labels_file}'\n",
                "assert embeddings_dir.exists(),     f'Embeddings dir not found: {embeddings_dir}'\n",
                "tile_count = len(list(embeddings_dir.glob('*.tif')))\n",
                "assert tile_count > 0, f'No .tif files in {embeddings_dir}'\n",
                "\n",
                "print(f'Labels:     {labels_file}')\n",
                "print(f'Embeddings: {embeddings_dir}  ({tile_count} tiles)')\n",
                "print(f'Output:     {output_file}')\n",
                "print(f'Test band:  rows {TEST_BAND_FRAC_LOW*100:.0f}%–{TEST_BAND_FRAC_HIGH*100:.0f}% of tile row range')\n",
                "print(f'Train:      north + south of that band')\n",
                "print(f'Train target: {sum(train_samples_per_class.values()):,}')\n",
                "print(f'Test target:  {sum(test_samples_per_class.values()):,}')\n",
                "print('Configuration validated!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 3: Discover tiles and split into middle band (test) vs north+south (train)\n",
                "print('=' * 70)\n",
                "print('DISCOVERING TILES — MIDDLE ROW BAND SPLIT')\n",
                "print('=' * 70)\n",
                "\n",
                "all_tile_files = sorted(embeddings_dir.glob('*.tif'))\n",
                "tile_info = []\n",
                "for tf in all_tile_files:\n",
                "    parts = tf.stem.split('-')\n",
                "    if len(parts) >= 3:\n",
                "        try: tile_info.append((int(parts[-2]), int(parts[-1]), tf))\n",
                "        except ValueError: pass\n",
                "\n",
                "if not tile_info:\n",
                "    raise RuntimeError('No parseable tiles — check tile naming (*-ROW-COL.tif)')\n",
                "\n",
                "# Determine test band row bounds from actual tile offsets\n",
                "all_row_offsets = sorted(set(r for r, c, p in tile_info))\n",
                "row_min = all_row_offsets[0]\n",
                "row_max = all_row_offsets[-1]\n",
                "total_row_range = row_max - row_min\n",
                "\n",
                "TEST_ROW_MIN = row_min + int(total_row_range * TEST_BAND_FRAC_LOW)\n",
                "TEST_ROW_MAX = row_min + int(total_row_range * TEST_BAND_FRAC_HIGH)\n",
                "\n",
                "# Snap to nearest actual tile row offsets\n",
                "TEST_ROW_MIN = min(all_row_offsets, key=lambda r: abs(r - TEST_ROW_MIN))\n",
                "TEST_ROW_MAX = min(all_row_offsets, key=lambda r: abs(r - TEST_ROW_MAX))\n",
                "\n",
                "test_tiles  = [p for r, c, p in tile_info if TEST_ROW_MIN <= r <= TEST_ROW_MAX]\n",
                "train_tiles = [p for r, c, p in tile_info if r < TEST_ROW_MIN or r > TEST_ROW_MAX]\n",
                "\n",
                "print(f'Total tiles:      {len(tile_info)}')\n",
                "print(f'Row offset range: {row_min} — {row_max}')\n",
                "print(f'Test band:        rows {TEST_ROW_MIN} — {TEST_ROW_MAX} '\n",
                "      f'({(TEST_ROW_MAX - TEST_ROW_MIN) / total_row_range * 100:.1f}% of range)')\n",
                "print(f'Train tiles (north + south): {len(train_tiles)}')\n",
                "print(f'Test  tiles (middle):        {len(test_tiles)}')\n",
                "\n",
                "if not test_tiles:\n",
                "    raise RuntimeError('No test tiles found. Adjust TEST_BAND_FRAC_LOW/HIGH.')\n",
                "if not train_tiles:\n",
                "    raise RuntimeError('No train tiles found.')\n",
                "\n",
                "print('\\nMiddle band split defined!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 4: Sample pixel coordinates from each split\n",
                "# All 6 classes are sampled geographically — no special cases needed.\n",
                "print('=' * 70)\n",
                "print('SAMPLING PIXEL COORDINATES')\n",
                "print('=' * 70)\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "def sample_coords_from_tiles(tile_paths, samples_per_class, split_name):\n",
                "    if not tile_paths:\n",
                "        raise RuntimeError(f'No tiles provided for {split_name}.')\n",
                "    tile_info_local = []\n",
                "    for tf in tile_paths:\n",
                "        parts = tf.stem.split('-')\n",
                "        try:\n",
                "            r = int(parts[-2]); c = int(parts[-1])\n",
                "            with rasterio.open(tf) as s:\n",
                "                tile_info_local.append((r, c, s.height, s.width))\n",
                "        except Exception: pass\n",
                "    if not tile_info_local:\n",
                "        raise RuntimeError(f'{split_name}: could not open any tiles.')\n",
                "\n",
                "    bbox_row_min = min(r   for r,c,h,w in tile_info_local)\n",
                "    bbox_row_max = max(r+h for r,c,h,w in tile_info_local)\n",
                "    bbox_col_min = min(c   for r,c,h,w in tile_info_local)\n",
                "    bbox_col_max = max(c+w for r,c,h,w in tile_info_local)\n",
                "    print(f'  {split_name} bbox: rows {bbox_row_min}–{bbox_row_max}, cols {bbox_col_min}–{bbox_col_max}')\n",
                "\n",
                "    sampled   = {cls: {'y': [], 'x': []} for cls in samples_per_class}\n",
                "    collected = {cls: 0 for cls in samples_per_class}\n",
                "\n",
                "    with rasterio.open(labels_file) as src:\n",
                "        windows = list(src.block_windows(1))\n",
                "        np.random.shuffle(windows)\n",
                "        for idx, (block_id, window) in tqdm(enumerate(windows), total=len(windows), desc=split_name):\n",
                "            r0 = window.row_off; c0 = window.col_off\n",
                "            rh = window.height;  cw = window.width\n",
                "            if r0+rh <= bbox_row_min or r0 >= bbox_row_max: continue\n",
                "            if c0+cw <= bbox_col_min or c0 >= bbox_col_max: continue\n",
                "            chunk = src.read(1, window=window)\n",
                "            for cls in samples_per_class:\n",
                "                if collected[cls] >= samples_per_class[cls]: continue\n",
                "                y_l, x_l = np.where(chunk == cls)\n",
                "                if len(y_l) == 0: continue\n",
                "                y_g = y_l + r0; x_g = x_l + c0\n",
                "                in_b = (y_g>=bbox_row_min)&(y_g<bbox_row_max)&(x_g>=bbox_col_min)&(x_g<bbox_col_max)\n",
                "                y_g = y_g[in_b]; x_g = x_g[in_b]\n",
                "                if len(y_g) == 0: continue\n",
                "                needed = samples_per_class[cls] - collected[cls]\n",
                "                if len(y_g) > needed:\n",
                "                    s = np.random.choice(len(y_g), needed, replace=False)\n",
                "                    y_g = y_g[s]; x_g = x_g[s]\n",
                "                sampled[cls]['y'].append(y_g)\n",
                "                sampled[cls]['x'].append(x_g)\n",
                "                collected[cls] += len(y_g)\n",
                "            if all(collected[c] >= samples_per_class[c] for c in samples_per_class):\n",
                "                print(f'  All collected after {idx+1} blocks'); break\n",
                "    print(f'  {split_name} summary:')\n",
                "    for cls in samples_per_class:\n",
                "        print(f'    Class {cls}: {collected[cls]:,} / {samples_per_class[cls]:,}')\n",
                "    return sampled\n",
                "\n",
                "train_sampled = sample_coords_from_tiles(train_tiles, train_samples_per_class, 'TRAIN (north+south)')\n",
                "test_sampled  = sample_coords_from_tiles(test_tiles,  test_samples_per_class,  'TEST  (middle band)')\n",
                "print('\\nCoordinate sampling complete!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 5: Consolidate and free memory\n",
                "\n",
                "def consolidate(sampled, budgets):\n",
                "    all_y, all_x, all_lbl = [], [], []\n",
                "    for cls in budgets:\n",
                "        if not sampled[cls]['y']: continue\n",
                "        ys = np.concatenate(sampled[cls]['y'])\n",
                "        xs = np.concatenate(sampled[cls]['x'])\n",
                "        if len(ys) > budgets[cls]: ys, xs = ys[:budgets[cls]], xs[:budgets[cls]]\n",
                "        all_y.append(ys); all_x.append(xs)\n",
                "        all_lbl.append(np.full(len(ys), cls, dtype=np.int64))\n",
                "    return np.concatenate(all_y), np.concatenate(all_x), np.concatenate(all_lbl)\n",
                "\n",
                "train_y, train_x, train_labels = consolidate(train_sampled, train_samples_per_class)\n",
                "del train_sampled; gc.collect()\n",
                "test_y, test_x, test_labels = consolidate(test_sampled, test_samples_per_class)\n",
                "del test_sampled; gc.collect()\n",
                "\n",
                "shuf = np.random.permutation(len(train_labels))\n",
                "train_y, train_x, train_labels = train_y[shuf], train_x[shuf], train_labels[shuf]; del shuf\n",
                "shuf = np.random.permutation(len(test_labels))\n",
                "test_y, test_x, test_labels = test_y[shuf], test_x[shuf], test_labels[shuf]\n",
                "del shuf; gc.collect()\n",
                "\n",
                "print(f'Train: {len(train_labels):,}  classes: {sorted(np.unique(train_labels).tolist())}')\n",
                "print(f'Test:  {len(test_labels):,}   classes: {sorted(np.unique(test_labels).tolist())}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 6: Extract embeddings\n",
                "print('\\n' + '=' * 70)\n",
                "print('EXTRACTING EMBEDDINGS')\n",
                "print('=' * 70)\n",
                "\n",
                "def extract_embeddings(tile_files, y_indices, x_indices, desc):\n",
                "    n = len(y_indices)\n",
                "    X = np.zeros((n, 64), dtype=np.float32)\n",
                "    found = np.zeros(n, dtype=bool)\n",
                "    with tqdm(total=len(tile_files), desc=desc, unit=' tiles') as pbar:\n",
                "        for tf in tile_files:\n",
                "            try:\n",
                "                with rasterio.open(tf) as src:\n",
                "                    if src.count != 64: pbar.update(1); continue\n",
                "                    parts = tf.stem.split('-')\n",
                "                    try: r_off = int(parts[-2]); c_off = int(parts[-1])\n",
                "                    except: pbar.update(1); continue\n",
                "                    th, tw = src.height, src.width\n",
                "                    mask = ((y_indices>=r_off)&(y_indices<r_off+th)&\n",
                "                            (x_indices>=c_off)&(x_indices<c_off+tw))\n",
                "                    if mask.any():\n",
                "                        tile_data = src.read()\n",
                "                        if tile_data.shape[0] != 64: pbar.update(1); continue\n",
                "                        ly = y_indices[mask] - r_off\n",
                "                        lx = x_indices[mask] - c_off\n",
                "                        vals = tile_data[:, ly, lx].T\n",
                "                        del tile_data\n",
                "                        valid = ~np.isnan(vals).any(axis=1)\n",
                "                        g_idx = np.where(mask)[0]\n",
                "                        X[g_idx[valid]] = vals[valid]\n",
                "                        found[g_idx[valid]] = True\n",
                "                        del vals\n",
                "            except Exception as e:\n",
                "                print(f'\\nError {tf.name}: {e}')\n",
                "            pbar.update(1)\n",
                "            pbar.set_postfix({'found': f'{found.sum():,}/{n:,}'})\n",
                "    print(f'  Extracted {found.sum():,} / {n:,}')\n",
                "    return X, found\n",
                "\n",
                "print('\\n-- TRAIN --')\n",
                "X_train_raw, train_found = extract_embeddings(all_tile_files, train_y, train_x, 'Train tiles')\n",
                "X_train = X_train_raw[train_found]\n",
                "y_train = train_labels[train_found]\n",
                "del X_train_raw, train_found, train_y, train_x, train_labels; gc.collect()\n",
                "print(f'X_train: {X_train.shape}  classes: {sorted(np.unique(y_train).tolist())}')\n",
                "\n",
                "print('\\n-- TEST --')\n",
                "X_test_raw, test_found = extract_embeddings(all_tile_files, test_y, test_x, 'Test tiles')\n",
                "X_test = X_test_raw[test_found]\n",
                "y_test = test_labels[test_found]\n",
                "del X_test_raw, test_found, test_y, test_x, test_labels; gc.collect()\n",
                "print(f'X_test: {X_test.shape}  classes: {sorted(np.unique(y_test).tolist())}')\n",
                "\n",
                "print('\\nExtraction complete!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 7: Compute class weights and save\n",
                "print('\\n' + '=' * 70)\n",
                "print('SAVING DATASET')\n",
                "print('=' * 70)\n",
                "\n",
                "unique_cls, counts = np.unique(y_train, return_counts=True)\n",
                "class_weights = np.zeros(6, dtype=np.float32)\n",
                "for cls, cnt in zip(unique_cls, counts):\n",
                "    class_weights[cls] = 1.0 / cnt\n",
                "class_weights = class_weights / class_weights.sum() * 6\n",
                "\n",
                "print('Class weights (from train):')\n",
                "for cls in range(6):\n",
                "    print(f'  Class {cls}: {class_weights[cls]:.4f}')\n",
                "\n",
                "np.savez_compressed(\n",
                "    output_file,\n",
                "    X_train=X_train, y_train=y_train,\n",
                "    X_test=X_test,   y_test=y_test,\n",
                "    class_weights=class_weights,\n",
                "    test_row_min=np.array(TEST_ROW_MIN, dtype=np.int64),\n",
                "    test_row_max=np.array(TEST_ROW_MAX, dtype=np.int64),\n",
                ")\n",
                "print(f'\\nSaved: {output_file}')\n",
                "print(f'  X_train: {X_train.shape}  |  X_test: {X_test.shape}')\n",
                "print(f'  test_row_min: {TEST_ROW_MIN}  test_row_max: {TEST_ROW_MAX}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CELL 8: Verification\n",
                "d = np.load(output_file)\n",
                "print(f'Arrays: {list(d.keys())}')\n",
                "print(f'X_train: {d[\"X_train\"].shape}  NaN={np.isnan(d[\"X_train\"]).any()}')\n",
                "print(f'X_test:  {d[\"X_test\"].shape}   NaN={np.isnan(d[\"X_test\"]).any()}')\n",
                "print(f'y_train classes: {sorted(np.unique(d[\"y_train\"]).tolist())}')\n",
                "print(f'y_test  classes: {sorted(np.unique(d[\"y_test\"]).tolist())}')\n",
                "print(f'test_row_min: {int(d[\"test_row_min\"])}  test_row_max: {int(d[\"test_row_max\"])}')\n",
                "d.close()\n",
                "print('Verification passed!')"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}